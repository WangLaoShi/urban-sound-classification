\section{Conclusions}
\label{results}

This last Section presents results obtained on the test sets. 
We test the best multilayer perceptron and the best convolutional network found.
As stated on the first Section, the five test sets are made out of the 
folds number five, seven, eight, nine and ten.

\subsection{Test set results}

\paragraph{Test set preprocessing}
The test sets are preprocessed with the same techniques used to extract the training sets.\\
In fact, regarding the MLP training set, the one with 180 features, all the features are extracted 
from the test audio files and scaled using the pre-fitted Standardscaler.
Similarly, each pixel in the test images is scaled using the Standardscaler 
fitted on the image training set.

\paragraph{Results}
The MLP model is the fine tuned one coming from the hyperparameter tuning phase, 
trained on the 180 features dataset, namely the \emph{Extended model}, 
while the CNN one is the best performer from the tried convolutional models, 
the so called $C_3$ network with 0.001 Adam learning rate and 32 batch size.
\begin{center}
    \begin{tabular}{ |l|r|r| } 
        \hline
        Test set & MLP Accuracy & CNN Accuracy\\
        \hline
        Fold 5 & 0.7425 & 0.5171\\
        Fold 7 & 0.6038 & 0.5668\\
        Fold 8 & 0.6873 & 0.5744\\
        Fold 9 & 0.6348 & 0.5515\\
        Fold 10 & 0.6858 & 0.5639\\ 
        \hline
    \end{tabular}
\end{center}

The mean accuracy and standard deviation are: 
\begin{center}
    \begin{tabular}{ |c|r|r| } 
        \hline
        Model & Mean accuracy & Standard deviation\\
        \hline
        MLP & 0.6708 & 0.0478 \\
        CNN & 0.5547 & 0.0202 \\
        \hline
    \end{tabular}
\end{center}

\subsection{Future works}

Results are better on MLP models, but CNNs
shows potential on the problem.
Results could be improved, indeed, 
a more refined training set creation can be made, by exploiting 
more features from the Librosa library, testing different type 
of scalers and experimenting with different feature selection 
techniques.

Regarding the image dataset, more channels could be considered 
by using more features as images, also, data augmentation techniques 
could be applied in order to increase the cardinality of the dataset.
Finally, with more computational power, a proper random search could be performed.