\section{Feature extraction}
\label{feature-extraction}

This Sections presents the original dataset structure and the 
steps followed to create training and test sets from it.

Note that the models mentioned in this section are
three layers \emph{multilayer perceptron}, 
a feed forward neural network where each layer 
is densely connected  to the following, 
with a reasonable number of neurons, trained 
for 100 epochs with default parameters for the \emph{stochastic gradient 
descent optimizer}.~\cite{mlp}\cite{sgd}\\
The accuracy on the training is computed with a \emph{cross-validation} 
approach.~\cite{cross}\\
A deeper discussion about the models structure as well as the validation
techniques used in the project can be found at Section \vref{model-definition}.

\subsection{Dataset structure}
\label{dataset-structure}

The UrbanSound8k dataset contains ten folds of audio samples, each one about 
four seconds long. The samples are divided in ten classes.\\
From the total of ten folds, the number one, two, three, four and six 
are taken as a training set, the others are each one a test set.
For this reason the following count about class numerosity considers
only the five training folds.

\begin{center}
    \begin{tabular}{ |l|c| } 
        \hline
        Class name & Number of samples \\
        \hline
        air conditioner & 500 \\
        car horn & 208 \\
        children playing & 500 \\
        dog bark & 500 \\
        drilling & 500 \\
        engine idling & 517 \\
        gun shot & 190 \\
        jackhammer & 548 \\
        siren & 536 \\
        street music & 500 \\
        \hline
    \end{tabular}
\end{center}

The table shows a clear class imbalance. In particular, the classes 
\emph{car horn} and \emph{gun shot} are not as numerous as the others. 
This can lead to poor performances on the these two categories, it is
therefore taken 
into consideration with training. 

The following table shows the number of samples in the training set and 
the various test sets.

\begin{center}
    \begin{tabular}{ |l|c| } 
        \hline
        Dataset & Number of samples \\
        \hline
        Training set & 4499 \\
        Test set 5 & 936 \\
        Test set 7 & 838 \\
        Test set 8 & 806 \\
        Test set 9 & 816 \\
        Test set 10 & 837 \\
        \hline
    \end{tabular}
\end{center}
All the operations on the datasets are performed with \emph{Pandas} library.~\cite{pandas}

\subsection{First dataset}
Extracting features from audio files is not straightforward, nonetheless there 
are a collection of audio characteristics that are commonly used in audio machine learning 
applications.~\cite{features}

To extract information from audio files \emph{Librosa} is used.~\cite{librosa}
The library provides many methods to choose from,
to keep it simple, for the first try with this dataset, the extracted features 
are these three ones: 
\begin{enumerate}
    \item \emph{Mel-frequency cepstral coefficients};
    \item \emph{Chromagram};
    \item \emph{Root-mean-square}.
\end{enumerate}
Each feature consists of an array of arrays containing measurements. 
A series of functions are applied to each sub-array and results 
are concatenated in a final feature vector. 
The functions applied are \emph{minimum}, \emph{maximum}, \emph{mean} 
and \emph{median} from the \emph{Numpy} library.~\cite{numpy}

This approach results in 132 components feature vectors.

\paragraph{Parallelizing feature extraction}
Extracting the three features listed above is really intensive 
but the task is easily parallelizable, in fact, each file is independent 
from one another.

For this purpose \emph{Dask} is used to speed up the computation and 
extract features from audio files in a multi-processing fashion.~\cite{dask}
The main idea is to build an execution plan, where each audio file 
is managed in parallel by a collection of workers. 
Improvement is great as the time to process a single fold 
is cutted into a third.

\paragraph{Feature scaling}
After testing some neural networks on the first dataset results 
are not promising. One of the reasons is the big difference in 
ranges among feature vector components, for instance, 
some audio characteristics are in the order of thousands while others 
range between zero and one.

To mitigate this effect a \emph{StandardScaler} from \emph{scikit learn} is applied.~\cite{scaler}
The result is a dataset where each feature has more or less a distribution 
centered in zero with unit variance.
This leads to an improvement on the results using the same
model as before. 


\subsection{Extended dataset}
\label{extended-dataset}

Results using the three features named in the previous Subsection 
are promising but not enough, thus, to improve accuracy on the training set, 
new audio characteristics are extracted, namely:
\begin{enumerate}
    \item \emph{Zero-crossing rate};
    \item \emph{Roll-off frequency};
    \item \emph{Spectral flux onset strength}.
\end{enumerate}
As before, \emph{minimum}, \emph{maximum}, \emph{mean} 
and \emph{median} are applied to each feature vector and 
results are concatenated, leading to 12 new features for each 
audio file.
Scaling yields to promising results on the first dataset, 
so the same approach is applied to the extended one.

After testing a network on the new training set 
we can see a better accuracy.

\paragraph{Feature selection}
Adding new features can lead to better results 
in the end but they all need to be useful to the model.
For this reason the extended dataset is subject of some experiments 
with feature selection, in particular \emph{PCA} algorithm from scikit
learn is applied.~\cite{pca}

The main idea is to select a reduced number of features from the total, 
without loosing information. This approach often leads to better results, 
as useless features are discarded.

After some experiments with the number of features to select, 120 out of 144
are selected. In this case PCA application leads to a small improvement
on the training set in terms of accuracy.

\newpage