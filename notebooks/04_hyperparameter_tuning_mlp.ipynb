{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "This notebook focuses on tuning the hyperparameters of an initial network to find a better model on the training set. \n",
    "The starting point is a 4 layered feed forward neural network with 120, 60, 25 and 10 neurons per layer.\n",
    "\n",
    "## Random search\n",
    "To reduce computation a random search is preferred to a complete grid search.\n",
    "A total of 100 models are tested."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.model import NeuralNetwork\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "def print_results(results):\n",
    "    print(\"Best: %f using %s\\n\" % (results.best_score_, results.best_params_))\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    params = results.cv_results_['params']\n",
    "    for mean, stdev, param in sorted(zip(means, stds, params), key=lambda x : -x[0])[:3]:\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    print(\"...\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "k = 2\n",
    "neurons = [(180, 80 + i*k, 46 + j*k, 10) for i in (-2,-1,0,1,2) for j in (-2,-1,0,1,2)]\n",
    "learning_rate = [0.001, 0.01, 0.1, 0.5]\n",
    "momentum = [0.0, 0.01, 0.1, 1]\n",
    "epochs = [60, 80, 100]\n",
    "batch_size = [32, 64]\n",
    "\n",
    "param_dist = dict(neurons=neurons, \n",
    "                  learning_rate=learning_rate,\n",
    "                  momentum=momentum, \n",
    "                  epochs=epochs, \n",
    "                  batch_size=batch_size)\n",
    "\n",
    "extended_results = NeuralNetwork.optimize_model(method=\"random\", \n",
    "                                                param_grid=param_dist,\n",
    "                                                dataset_path=\"../data/processed/extended/train_pca.csv\", \n",
    "                                                iterations=50)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print_results(extended_results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.630796 using {'neurons': (180, 80, 44, 10), 'momentum': 0.1, 'learning_rate': 0.1, 'epochs': 100, 'batch_size': 32}\n",
      "\n",
      "0.630796 (0.036974) with: {'neurons': (180, 80, 44, 10), 'momentum': 0.1, 'learning_rate': 0.1, 'epochs': 100, 'batch_size': 32}\n",
      "0.626793 (0.051451) with: {'neurons': (180, 80, 42, 10), 'momentum': 0.01, 'learning_rate': 0.1, 'epochs': 60, 'batch_size': 32}\n",
      "...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "param_dist[\"neurons\"] = [(102, 45 + i*k, 30 + j*k, 10) for i in (-2,-1,0,1,2) for j in (-2,-1,0,1,2)]\n",
    "\n",
    "pca_results = NeuralNetwork.optimize_model(method=\"random\", \n",
    "                                           param_grid=param_dist,\n",
    "                                           dataset_path=\"../data/processed/extended/train_pca.csv\", \n",
    "                                           iterations=50)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print_results(pca_results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.625463 using {'neurons': (102, 45, 28, 10), 'momentum': 0.1, 'learning_rate': 0.1, 'epochs': 100, 'batch_size': 32}\n",
      "\n",
      "0.625463 (0.041491) with: {'neurons': (102, 45, 28, 10), 'momentum': 0.1, 'learning_rate': 0.1, 'epochs': 100, 'batch_size': 32}\n",
      "0.617906 (0.040060) with: {'neurons': (102, 45, 26, 10), 'momentum': 0.01, 'learning_rate': 0.1, 'epochs': 60, 'batch_size': 32}\n",
      "...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final model\n",
    "The best model found is the following"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "\n",
    "best_param = extended_results.best_params_\n",
    "best_param"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'neurons': (180, 80, 44, 10),\n",
       " 'momentum': 0.1,\n",
       " 'learning_rate': 0.1,\n",
       " 'epochs': 100,\n",
       " 'batch_size': 32}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test results\n",
    "\n",
    "The final model is evaluated on the test set to determine performances."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "p = extended_results.best_params_\n",
    "\n",
    "model = NeuralNetwork.create_model(neurons=p[\"neurons\"],\n",
    "                                   learning_rate=p[\"learning_rate\"], \n",
    "                                   momentum=p[\"momentum\"])\n",
    "\n",
    "from src.data import Dataset\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "d = Dataset(dataset_path=\"../data/processed/extended/train_pca.csv\", \n",
    "            test_size=0)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "stopper = EarlyStopping(monitor='accuracy', patience=3, verbose=1)\n",
    "fit_params = dict(callbacks=[stopper])\n",
    "\n",
    "x, y = d.get_splits()\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "weights_dict = dict(zip(np.unique(y), class_weights))\n",
    "\n",
    "model.fit(x, y, class_weight=weights_dict, epochs=p[\"epochs\"], batch_size=p[\"batch_size\"], verbose=0, **fit_params)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f56242e1310>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from src.utils import show_accuracy_loss\n",
    "\n",
    "accuracy, loss = show_accuracy_loss(model, scaling=\"pca\", test_dataset_path=\"../data/processed/extended\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 1.6338 - accuracy: 0.6592\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.1878 - accuracy: 0.6098\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.0602 - accuracy: 0.7667\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.1773 - accuracy: 0.6360\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8852 - accuracy: 0.6858\n",
      "\n",
      "Accuracy:\n",
      "\tMean: 0.671506917476654 \n",
      "\tStandard deviation: 0.05384217473067788\n",
      "\n",
      "Loss:\n",
      "\tMean: 2.1888545989990233 \n",
      "\tStandard deviation: 0.5279860807927551\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}