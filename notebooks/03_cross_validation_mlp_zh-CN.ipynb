{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 分层交叉验证\n",
        "\n",
        "该笔记本的目标是比较获得的四个训练集，以决定在哪一个上运行超参数调整阶段。\n",
        "\n",
        "对每个数据集进行测试的模型都是默认神经网络，其隐藏神经元的数量等于输入加上输出的三分之二。参数保持默认，训练持续 100 个时期。\n",
        "\n",
        "进行分层交叉验证来解决训练集中的类别不平衡问题，同时在训练时考虑类别权重。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from src.model import NeuralNetwork\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.utils import class_weight\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "tensorflow.random.set_seed(1)\n",
        "import warnings  \n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "def get_cross_scores(path, neurons, optimizer=\"sgd\", epochs=100):\n",
        "    data = pd.read_csv(path)\n",
        "    x = data.drop(\"class\", axis=1)\n",
        "    y = data[\"class\"]\n",
        "    \n",
        "    kf = StratifiedKFold(n_splits=5)\n",
        "    \n",
        "    class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                      np.unique(y),\n",
        "                                                      y)\n",
        "    weights_dict = dict(zip(np.unique(y), class_weights))\n",
        "    acc=[]\n",
        "    loss=[]\n",
        "\n",
        "    for train_index, test_index in kf.split(x, y):\n",
        "        net = NeuralNetwork.create_model(neurons=neurons, optimizer=optimizer)\n",
        "        net.fit(x.iloc[train_index], \n",
        "                y.iloc[train_index],\n",
        "                batch_size=64, \n",
        "                epochs=epochs, \n",
        "                verbose=0, \n",
        "                class_weight=weights_dict)\n",
        "        scores = net.evaluate(x.iloc[test_index], \n",
        "                              y.iloc[test_index], verbose=1)\n",
        "        acc.append(scores[1])\n",
        "        loss.append(scores[0])\n",
        "    \n",
        "    return {\"Accuracy\" : (np.mean(acc), np.std(acc), acc),\n",
        "            \"Loss\" : (np.mean(loss), np.std(loss), loss)}"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 第一个未缩放的数据集\n",
        "第一个模型在未缩放的数据集上进行测试，该数据集有 132 个特征。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "res_1 = get_cross_scores(\"../data/processed/initial/train_unscaled.csv\", (132, 60, 30, 10))\n",
        "pprint(res_1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /home/fran/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.1111\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 2.3026 - accuracy: 0.1111\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 54869046067200.0000 - accuracy: 0.1211\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 2.3009 - accuracy: 0.1144\n",
            "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.1112\n",
            "{'Accuracy': (0.11380249559879303,\n",
            "              0.0038706225007881373,\n",
            "              [0.1111111119389534,\n",
            "               0.1111111119389534,\n",
            "               0.12111110985279083,\n",
            "               0.11444444209337234,\n",
            "               0.11123470216989517]),\n",
            " 'Loss': (nan,\n",
            "          nan,\n",
            "          [nan, 2.3026485443115234, 54869046067200.0, 2.300891160964966, nan])}\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 第一个缩放数据集\n",
        "第二个模型在缩放后的数据集、132 个特征和标准缩放器上进行测试"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "res_2 = get_cross_scores(\"../data/processed/initial/train_scaled.csv\", (132, 60, 30, 10))\n",
        "pprint(res_2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 2ms/step - loss: 2.0357 - accuracy: 0.5667\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 2.1175 - accuracy: 0.5644\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 2.0790 - accuracy: 0.6378\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 2.3364 - accuracy: 0.5478\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 2.3352 - accuracy: 0.5551\n",
            "{'Accuracy': (0.5743455648422241,\n",
            "              0.03242956403450645,\n",
            "              [0.5666666626930237,\n",
            "               0.5644444227218628,\n",
            "               0.6377778053283691,\n",
            "               0.5477777719497681,\n",
            "               0.5550611615180969]),\n",
            " 'Loss': (2.180751657485962,\n",
            "          0.12919648526724084,\n",
            "          [2.0357139110565186,\n",
            "           2.1174960136413574,\n",
            "           2.078993558883667,\n",
            "           2.3363943099975586,\n",
            "           2.335160493850708])}\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 扩展和缩放数据集\n",
        "该数据集具有更多特征，144 个特征和标准缩放器"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "res_3 = get_cross_scores(\"../data/processed/extended/train_extended.csv\", (180, 80, 46, 10))\n",
        "pprint(res_3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 2ms/step - loss: 1.9908 - accuracy: 0.6311\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 1.6214 - accuracy: 0.6556\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 1.9871 - accuracy: 0.7200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 1.8170 - accuracy: 0.5922\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 2.0544 - accuracy: 0.5829\n",
            "{'Accuracy': (0.63635174036026,\n",
            "              0.049398414649388336,\n",
            "              [0.6311110854148865,\n",
            "               0.6555555462837219,\n",
            "               0.7200000286102295,\n",
            "               0.5922222137451172,\n",
            "               0.582869827747345]),\n",
            " 'Loss': (1.894150710105896,\n",
            "          0.1574803493676554,\n",
            "          [1.990844488143921,\n",
            "           1.6214247941970825,\n",
            "           1.9870859384536743,\n",
            "           1.816994309425354,\n",
            "           2.0544040203094482])}\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA 数据集\n",
        "这是一个缩小的扩展缩放数据集，包含由 PCA 发现的 120 个特征"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "res_4 = get_cross_scores(\"../data/processed/extended/train_pca.csv\", (102, 45, 30, 10))\n",
        "pprint(res_4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 1ms/step - loss: 1.7017 - accuracy: 0.6456\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 1.7804 - accuracy: 0.6289\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 2.1057 - accuracy: 0.6744\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 2.2389 - accuracy: 0.5900\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 2.5394 - accuracy: 0.5551\n",
            "{'Accuracy': (0.6187900066375732,\n",
            "              0.041966724167351435,\n",
            "              [0.6455555558204651,\n",
            "               0.6288889050483704,\n",
            "               0.6744444370269775,\n",
            "               0.5899999737739563,\n",
            "               0.5550611615180969]),\n",
            " 'Loss': (2.0732010126113893,\n",
            "          0.3064759477588344,\n",
            "          [1.701684594154358,\n",
            "           1.7803637981414795,\n",
            "           2.1056747436523438,\n",
            "           2.2388598918914795,\n",
            "           2.539422035217285])}\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "最终决定\n",
        "\n",
        "选定进行超参数调整的模型是最后两个，因为性能更好。"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit"
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}