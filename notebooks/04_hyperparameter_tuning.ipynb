{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "This notebook focuses on tuning the hyperparameters of an initial network to find a better model on the training set. \n",
    "The starting point is a 4 layered feed forward neural network with 120, 60, 25 and 10 neurons per layer.\n",
    "\n",
    "## Random vs grid search\n",
    "To reduce computation a random search is preferred to a complete grid search.\n",
    "Later, the model obtained with the random search will be finetuned with a grid search to optimize it locally, \n",
    "also, 5 fold cross validation is performed when testing a model.\n",
    "\n",
    "The total possible models are 400, the randm search tries with only 100.\n",
    "Also, the fit implements an early stopper."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.model import NeuralNetwork"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "k = 2\n",
    "neurons = [(120, 60 + i*k, 25 + j*k, 10) for i in (-2,-1,0,1,2) for j in (-2,-1,0,1,2)]\n",
    "\n",
    "learning_rate = [0.001, 0.01, 0.1, 0.5]\n",
    "momentum = [0.0, 0.01, 0.1, 1]\n",
    "epochs = [100]\n",
    "batch_size = [32]\n",
    "\n",
    "param_dist = dict(neurons=neurons, \n",
    "                  learning_rate=learning_rate,\n",
    "                  momentum=momentum, \n",
    "                  epochs=epochs, \n",
    "                  batch_size=batch_size)\n",
    "\n",
    "results = NeuralNetwork.optimize_model(method=\"random\", \n",
    "                                       param_grid=param_dist,\n",
    "                                       dataset_path=\"../data/processed/extended/train_pca.csv\", \n",
    "                                       iterations=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(\"Best: %f using %s\\n\" % (results.best_score_, results.best_params_))\n",
    "means = results.cv_results_['mean_test_score']\n",
    "stds = results.cv_results_['std_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, stdev, param in sorted(zip(means, stds, params), key=lambda x : -x[0])[:5]:\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print(\"...\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.585677 using {'neurons': (120, 62, 27, 10), 'momentum': 0.1, 'learning_rate': 0.1, 'epochs': 100, 'batch_size': 32}\n",
      "\n",
      "0.585677 (0.071518) with: {'neurons': (120, 62, 27, 10), 'momentum': 0.1, 'learning_rate': 0.1, 'epochs': 100, 'batch_size': 32}\n",
      "0.583235 (0.072438) with: {'neurons': (120, 56, 23, 10), 'momentum': 0.0, 'learning_rate': 0.1, 'epochs': 100, 'batch_size': 32}\n",
      "0.580792 (0.084351) with: {'neurons': (120, 64, 23, 10), 'momentum': 0.1, 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32}\n",
      "0.579233 (0.085570) with: {'neurons': (120, 64, 25, 10), 'momentum': 0.1, 'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32}\n",
      "0.576124 (0.075047) with: {'neurons': (120, 58, 25, 10), 'momentum': 0.0, 'learning_rate': 0.1, 'epochs': 100, 'batch_size': 32}\n",
      "...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine tune random result with grid search\n",
    "To try further optimization, the random search result is fine tuned with grid search."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "results.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'neurons': (120, 62, 27, 10),\n",
       " 'momentum': 0.1,\n",
       " 'learning_rate': 0.1,\n",
       " 'epochs': 100,\n",
       " 'batch_size': 32}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "param_grid = dict(neurons=[(120, 62 + i, 27 + j, 10) for i in [-1,0,1] for j in [-1,0,1]], \n",
    "                  learning_rate=[0.08, 0.1, 0.12],\n",
    "                  momentum=[0.08, 0.1, 0.12], \n",
    "                  epochs=[100], \n",
    "                  batch_size=[32])\n",
    "\n",
    "grid_results = NeuralNetwork.optimize_model(method=\"grid\", \n",
    "                                            param_grid=param_grid,\n",
    "                                            dataset_path=\"../data/processed/extended/train_pca.csv\")\n",
    "\n",
    "print(\"Best: %f using %s\\n\" % (grid_results.best_score_, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "for mean, stdev, param in sorted(zip(means, stds, params), key=lambda x : -x[0])[:5]:\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print(\"...\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best: 0.587674 using {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.08, 'momentum': 0.12, 'neurons': (120, 62, 28, 10)}\n",
      "\n",
      "0.587674 (0.076336) with: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.08, 'momentum': 0.12, 'neurons': (120, 62, 28, 10)}\n",
      "0.586790 (0.084240) with: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.1, 'momentum': 0.1, 'neurons': (120, 62, 26, 10)}\n",
      "0.583673 (0.086433) with: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.08, 'momentum': 0.08, 'neurons': (120, 61, 28, 10)}\n",
      "0.583243 (0.084687) with: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.12, 'momentum': 0.08, 'neurons': (120, 63, 27, 10)}\n",
      "0.582332 (0.074344) with: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.08, 'momentum': 0.12, 'neurons': (120, 62, 26, 10)}\n",
      "...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "\n",
    "Performing grid search on the random search result led to a really small improvement to the model, but it's still a positive result.\n",
    "\n",
    "Let's now test this model performances on the test sets to find how it performs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "p = grid_results.best_params_\n",
    "\n",
    "model = NeuralNetwork.create_model(neurons=p[\"neurons\"],\n",
    "                                   learning_rate=p[\"learning_rate\"], \n",
    "                                   momentum=p[\"momentum\"])\n",
    "\n",
    "from src.data import Dataset\n",
    "\n",
    "d = Dataset(dataset_path=\"../data/processed/extended/train_pca.csv\", \n",
    "            test_size=0)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "stopper = EarlyStopping(monitor='accuracy', patience=3, verbose=1)\n",
    "fit_params = dict(callbacks=[stopper])\n",
    "model.fit(*d.get_splits(), epochs=p[\"epochs\"], batch_size=p[\"batch_size\"], verbose=0, **fit_params)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 00019: early stopping\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7a8439c0a0>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from src.utils import show_accuracy_loss\n",
    "\n",
    "accuracy, loss = show_accuracy_loss(model, scaling=\"pca\", test_dataset_path=\"../data/processed/extended\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 1.8371 - accuracy: 0.6731\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.4221 - accuracy: 0.6301\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9238 - accuracy: 0.7184\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.7186 - accuracy: 0.6630\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3010 - accuracy: 0.6906\n",
      "\n",
      "Accuracy:\n",
      "\tMean: 0.6750125050544739 \n",
      "\tStandard deviation: 0.029288029064255778\n",
      "\n",
      "Loss:\n",
      "\tMean: 2.440521240234375 \n",
      "\tStandard deviation: 0.3727582139497537\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}